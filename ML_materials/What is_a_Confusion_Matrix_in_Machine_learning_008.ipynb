{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of regression, we can find out the correctness using the score and coefficient of determination.<br>\n",
    "Here we will explore various methods for understanding the correctness and efficiency of algorithms.<br>\n",
    "## Accuracy:\n",
    "Accuracy gives us a fraction of the correct predictions made. If it's '1' then for a given testing sample of variables the predicted variables match the testing sample.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score : 0.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = [0, 2, 1, 3]\n",
    "y_true = [0, 1, 2, 3]\n",
    "print(\"Score :\", accuracy_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then only 2 values are predicted correctly out of 4 then the accuracy is 2/4 or 0.5.\n",
    "Why accuracy is not the best option?\n",
    "Suppose we have an unbalanced dataset consisting of 95 '0''s and 5 '1's and the algorithm predicts 0 every time an input is given.\n",
    "Then even when we get 95% accuracy when it had to detect '1' it is wrong."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Confusion Matrix**\n",
    "Confusion matrix is useful in that we can assess how many predictions the model got right, and we understand that the model is performing in this particular way so we can think about how we can further improve our model.</p>\n",
    "<p>There are some terms that one must know regarding confusion matrices.</p>\n",
    "<ol>\n",
    "    <li><b>True Positives:</b> This is the number of samples predicted positive which were actually positive.</li>\n",
    "    <li><b>True Negatives:</b> This is the number of samples predicted negative which were actually negative.</li>\n",
    "    <li><b>False Positives:</b> This is the number of samples predicted positive which were <b>not</b> actually positive.</li>\n",
    "    <li><b>False Negatives:</b> This is the number of samples predicted negative which were <b>not</b> actually negative.</li>\n",
    "</ol>\n",
    "<p>In the case of multi-class classification, however, the confusion matrix shows the number of samples predicted correctly and wrongly for each class instead of true positives etc.</p>    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(solver = 'liblinear')\n",
    "clf.fit(x_train, y_train)\n",
    "y_train_pred = clf.predict(x_train)\n",
    "y_test_pred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[37,  0,  0],\n",
       "       [ 0, 28,  6],\n",
       "       [ 0,  0, 41]], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13,  0,  0],\n",
       "       [ 0, 10,  6],\n",
       "       [ 0,  0,  9]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_test_pred)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3dfac027262927982790583fc11aace72addb35d60841fa2981b59a23fc0f5c6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
