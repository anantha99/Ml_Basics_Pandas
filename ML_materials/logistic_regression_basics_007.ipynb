{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "It is a statistical method for analyzing a dataset in which there are one or more independent variable determines an outcome.<br>\n",
    "It is a type of classification algorithm.<br>\n",
    "### Classification algorithm\n",
    "It is a type of supervised learning technique that is used to categorize the new observations into different classes unlike they are not continuous like linear regression.<br>\n",
    "Ex:In the case of spam detection in e-mails. An email can be spam or not spam. There is no in-between state.<br>\n",
    "We use the sigmoid function to help us make a similar conclusion in logistic regression. We want to get the output as either 0 or 1. We make use of probability where a threshold point will be\n",
    "assigned. let's say 0.5 and if we get the output greater than the threshold it will be given as 1 and less than the threshold will be given as 0.<br>\n",
    "##### There are 2 types of classification<br>\n",
    "**Binary classification**<br>\n",
    "**Multiclass Classification**<br>\n",
    "Both of these can be better understood using examples.<br>\n",
    "#### Binary classification :\n",
    "There will be only 2 separations or classifications that have to be done. Like spam or not spam.\n",
    "#### Multiclass Classification:\n",
    "Here the output has to be divided into multiple separations like a given number has to be recognised and separated to which number it belongs.<br>\n",
    "There are 2 types:<br>\n",
    "#### OVR(one V/S rest)\n",
    "Also known as one-vs-all, the one-vs-rest model is a defined heuristic method that leverages a binary classification algorithm for multi-class classifications. The technique involves splitting a multi-class dataset into multiple sets of binary problems.<br>\n",
    "For instance, with a multi-class classification problem with red, green, and blue datasets, binary classification can be categorized as follows:<br>\n",
    "Problem one: red vs. green/blue<br>\n",
    "Problem two: blue vs. green/red<br>\n",
    "Problem three: green vs. blue/red<br>\n",
    "#### OVO(one V/S one)\n",
    "Like the one-vs-rest model, the one-vs-one is another excellent heuristic method that takes advantage of the binary classification algorithm for classifying multi-class datasets.<br>\n",
    "For instance, taking into consideration multi-class dataset problems with four classes - blue, red, green and yellow - the one-vs-one approach splits it into the following six binary classification datasets:<br>\n",
    "Problem 1: red vs. green<br>\n",
    "Problem 2: red vs. blue<br>\n",
    "Problem 3: red vs. yellow<br>\n",
    "Problem 4: green vs. yellow<br>\n",
    "Problem 5: blue vs. green<br>\n",
    "Problem 6: blue vs. yellow<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be reading the dataset and we have to take all the features that can influence the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(r'C:\\Users\\Ananthapadmanabha\\Desktop\\Ml_Basics_Pandas\\titanic_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the titanic dataset and being male or female also influenced the output so we'll convert the data into binary to be able to train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['sex_factor'] = pd.factorize(train_data.Sex)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After analyzing the data set we only consider these columns for training ['SibSp','Pclass','sex_factor','Fare','Parch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_taken_for_training = ['SibSp','Pclass','sex_factor','Fare','Parch']\n",
    "X = train_data[columns_taken_for_training]\n",
    "Y = train_data.Survived"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we use the train_test_split() to divide the dataset into training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size = 0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We call the logistic regression function and fit the training data using the fit() function. thne using the X_test we predict the Y_pred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cld = LogisticRegression(C=2,tol=0.001,penalty='l2',solver='sag',max_iter=2000)\n",
    "cld.fit(X_train,Y_train)\n",
    "Y_pred = cld.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check how accurate our predictions are we use the X_test and Y_test and get a value. In score() '1' is the ideal value. Here we are getting a value of '0.7'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7389830508474576"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cld.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[167,   7],\n",
       "       [ 70,  51]], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(Y_test,Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.96      0.81       174\n",
      "           1       0.88      0.42      0.57       121\n",
      "\n",
      "    accuracy                           0.74       295\n",
      "   macro avg       0.79      0.69      0.69       295\n",
      "weighted avg       0.78      0.74      0.71       295\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test,Y_pred))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3dfac027262927982790583fc11aace72addb35d60841fa2981b59a23fc0f5c6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
